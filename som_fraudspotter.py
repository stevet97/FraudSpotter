# -*- coding: utf-8 -*-
"""SOM : FraudSpotter

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FZUH4UFWwXUz2Ye1rK98B1Q7JByzjttr

**Imports and Setup**
"""

# Install necessary packages first
!pip install minisom numpy pandas matplotlib scikit-learn

#Import necessary libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from minisom import MiniSom

#Setup Google Drive
from google.colab import drive
drive.mount('/content/drive')

"""**Load Dataset - Refactored**"""

#Load Dataset Function
def load_dataset(file_path):
    try:
        df = pd.read_csv(file_path)
        print("Dataset Loaded Successfully.")
        return df
    except FileNotFoundError:
        print("File not found. Please check the path.")
    except pd.errors.EmptyDataError:
        print("File is empty. Please check the contents.")
    return None

#File path parameterized
file_path = '/content/drive/My Drive/SOM/Credit_Card_Applications.csv'
dataset = load_dataset(file_path)

if dataset is not None:
    print(dataset.head())  # Display first 5 rows for verification

"""**Data Preprocessing**"""

# Split dataset into features and labels
def preprocess_data(dataset):
    x = dataset.iloc[:, :-1].values  # Use all rows, all columns except the last one as features
    y = dataset.iloc[:, -1].values   # Use all rows, the last column as labels

    # Feature Scaling
    sc = MinMaxScaler(feature_range=(0, 1))
    x = sc.fit_transform(x)

    return x, y, sc

# Preprocess the data
x, y, sc = preprocess_data(dataset)
print(f"Number of features: {x.shape[1]}")

"""**Training Self-Organizing Map (SOM)**"""

# Train the SOM Function
def train_som(data, x_dim=8, y_dim=8, input_len=15, sigma=1.0, learning_rate=0.5, num_iterations=100):
    som = MiniSom(x=x_dim, y=y_dim, input_len=input_len, sigma=sigma, learning_rate=learning_rate)
    som.random_weights_init(data)
    som.train_random(data=data, num_iteration=num_iterations)
    return som

# Train SOM
som = train_som(x, input_len=x.shape[1])

# Display SOM Summary
print("SOM Trained Successfully.")

"""**Visualization Improvements**"""

# Visualize the results Function
def plot_som(som):
    plt.figure(figsize=(10, 10))
    plt.title("SOM Distance Map")
    plt.xlabel("SOM Grid X-axis")
    plt.ylabel("SOM Grid Y-axis")
    plt.pcolor(som.distance_map().T)
    plt.colorbar(label='Distance')
    plt.show()

# Plot SOM's distance map
plot_som(som)

"""**Find Frauds and Export Results**"""

# Identify Potential Frauds Function
def identify_frauds(som, data):
    mappings = som.win_map(data)

    # Example: Hard-coded neuron locations representing outliers (you might need more logic here)
    frauds_list = []

    # Add neurons to list of frauds if they contain data points
    for coordinates in [(6, 2), (1, 1)]:
        if coordinates in mappings and len(mappings[coordinates]) > 0:
            frauds_list.extend(mappings[coordinates])  # Add all data points mapped to this neuron

    frauds = np.array(frauds_list)
    return frauds

# Find Fraudulent Data Points
frauds = identify_frauds(som, x)

# Convert fraudulent data points back to their original scale
frauds_original_scale = sc.inverse_transform(frauds) if len(frauds) > 0 else []

# Export Fraudulent Data
def save_frauds_to_csv(frauds_data, output_path='fraudulent_records.csv'):
    if len(frauds_data) > 0:
        df_frauds = pd.DataFrame(frauds_data)
        df_frauds.to_csv(output_path, index=False)
        print(f"Fraudulent data points saved to {output_path}")
    else:
        print("No fraudulent data points found to save.")

save_frauds_to_csv(frauds_original_scale)